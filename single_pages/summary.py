# -*- coding: utf-8 -*-
"""model.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OyLkL0GBBYQfjxEn-tBbxwQjgPgjxCVT
"""

# get_model_binary.py의 실행을 통해 저장한 모델을 사용해 테스트를 진행한다.

import torch
from transformers import PreTrainedTokenizerFast, BartModel
from transformers.models.bart import BartForConditionalGeneration
from .utils.train import KoBARTConditionalGeneration

from .utils.papago import get_translate
from .utils.preprocessing import text_preprocessing
# from utils.inference_sentiment import RobertModel # layer key error
# from utils.inference_rqt import Song_rqt

import argparse
import yaml

hparams_path = './Summarization/logs/tb_logs/default/version_7/hparams.yaml'
model_binary_path = './Summarization/logs/model_chp/epoch=09-val_loss=1.582.ckpt'

def get_model_binary(self):

  parser = argparse.ArgumentParser()
  parser.add_argument("--hparams", default=None, type=str)
  parser.add_argument("--model_binary", default=None, type=str)
  parser.add_argument("--output_dir", default='./Summarization/kobart_summary', type=str)
  args = parser.parse_args()

  with open(args.hparams) as f:
      hparams = yaml.load(f)
        
  inf = KoBARTConditionalGeneration.load_from_checkpoint(args.model_binary, hparams=hparams)
  inf.model.save_pretrained(args.output_dir)


def KoBART2Image(lyrics):

  # model = BartForConditionalGeneration.from_pretrained('./Summarization/kobart_summary')
  model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-base-v1')
  tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')
  pre_lyrics = text_preprocessing(lyrics)


  if pre_lyrics:
      input_ids = tokenizer.encode(pre_lyrics)
      input_ids = torch.tensor(input_ids)
      input_ids = input_ids.unsqueeze(0)
      output = model.generate(input_ids, 
                              eos_token_id=1, 
                              max_length=32,
                              num_beams=3,  # 단어(토큰) 기준 양방향 참고할 단어(토큰) 개수
                              length_penalty=1.1) # 1보다 클 경우 조금 더 긴 문장 생성 유도
      output = tokenizer.decode(output[0], skip_special_tokens=True)

  # print(f'원문 가사 (한글) : {output}')
  trans_text = get_translate(output)
  # senti_lyrics = RobertModel.predict_sentiment(trans_text) # layer keyerror
  print(f'요약된 가사 (영문화) : {trans_text}')
  result_trans = str(trans_text)
  final_result = str('a painting of ' + result_trans )
  # print('\n')
  # print(f'이미지모델 삽입 문장 : {final_result}') 
  # result_txtimg = Song_rqt.generate_img(final_result)
  
  return final_result 




